Our next guest needs no introduction, so
I'm not going to bother introducing him,
Sam Alman. I will just say Sam is now
three for three and joining us to share
his thoughts at the three AI events that
we've had, which we really appreciate.
So, I just want to say thank you for
being here. This was our first office.
That's right. Oh, that's right. Say that
again. Yeah, this was this was our first
office. So, it's nice to be back. Let's
go back to the first office here. He
started in 2016.
2016. We just had Jensen here who said
that he delivered the first GGX1 system
over here. He did. Yeah. It's amazing
how small that thing looks now. Oh.
Versus what? Well, the current boxes are
still huge. But yeah, it was a fun
throwback. How heavy was it? That was
still when you could kind of like lift
one yourself.
He said it was about 70 lbs. Yeah. I
mean, it was heavy, but you could carry
it. So, um, did you imagine that you'd
be here today in 2016?
Uh, no. It was like, uh, we were sitting
over there and there were, you know, 14
of us or something and you were hacking
on this new system. I mean, even that
was like a we were sitting around like
looking at whiteboards trying to talk
about what we should do. Like this was a
ve it's almost impossible to sort of
overstate how
much we were like a research lab with no
with with a very strong belief and
direction and conviction but no real
kind of like action plan. I mean, not
only was like the idea of a company or a
product sort of unimaginable, the spec
like LLMs as an idea were still very far
off. And so, trying to play video games.
Trying to play video games. Are you
still trying to play video games? Now,
we're pretty good at that.
Um, all right. So, um, it took you
another six years for the first consumer
product to come out, which is ChatGpt.
along the way. How did you sort of think
about milestones to get something to
that level as like an accident of
history? The the uh the first consumer
product was not Chacht. That's right. It
was Dolly. Um the first product was uh
the
API. So we had built, you know, we kind
of went through a few different things.
We we were we had a a few directions
that we really wanted to bet on.
Eventually, as I mentioned, we said,
"Well, we got to build a system to see
if it's working. And we're not just
writing research papers. So, we're going
to see if we can, you know, play a video
game. Well, we're going to see if we can
do a robot hand. We're going to see if
we can do a few other things. And at
some point in there, uh, one person and
then initially and then eventually a
team got excited about trying to do
unsupervised learning and to build
language models. And that led to GPT1
and then GPT2 and and and by the time of
GBT3, we both thought we had something
that was kind of cool, but we couldn't
figure out what to do with it. Um, and
also we realized we needed a lot more
money to keep scaling. You know, we had
done GBD3, we wanted to go to GPT4. We
were heading into the world of
billion-dollar models. It's like hard to
do those as a pure science experiment
unless you're like a particle
accelerator or something. Um, even then
it's hard. So, we started thinking,
okay, we we both need to figure out how
this can become a business that can
sustain the investment that it requires.
And also like we have a sense that this
is heading towards something actually
useful and we had put GPT2 out as model
weights and not that much had happened.
Um one of the things that I had just
observed about
uh companies products in general is if
you do an API it usually works somehow
on the upside. This was like true across
many many YC companies. And also that if
you make something much easier to use,
there's usually a huge benefit to that.
So we're like, well, it's kind of hard
to run these models, they're getting
big, we'll go write some software, do a
really good job of running them. And and
also we'll then rather than build a
product cuz we couldn't figure out what
to build. Um we will hope that somebody
else finds something to build. And so I
forget exactly when, but maybe it was
like June of 2020. Um, we put out GPT3
in the API
and the world didn't care, but sort of
Silicon Valley did. They're like, "Oh,
this is kind of cool. This is pointing
at something." And there was this weird
thing where like we got almost no
attention from most of the world. And
some startup founders uh were like, "Oh,
this is really cool." Or like I mean
some of them are like this is AGI. Um,
the only people that
built real businesses with the GPT3 API
that I can remember were these company a
few companies that did like
copyrightiting as a service. That was
kind of the only thing GPT3 was over the
economic threshold on.
Um, but one thing we did notice which
eventually led to ChatGpt is even though
people couldn't build a lot of great
businesses with the GPT3 API, people
love to talk to it in the playground.
And it was terrible at chat. We had not
at that point figured out how to do RHF
to make it easy to chat with, but people
loved to do it anyway.
And in some sense, that was the kind of
only killer use other than copyrighting
of the API product that led us to
eventually build chat GPT. By the time
Chat GPT 3.5 came out, there were maybe
like eight categories instead of one
category where you could build a
business with the API. Um but but our
conviction that like people just want to
talk to the model had gotten really
strong. So we had done Dolly and Dolly
was doing okay but we knew we kind of
wanted to build especially along with um
the finetuning we were able to do we
knew we wanted to build this model this
product to let you talk to the model
and it launched in 2022 or something uh
I think yeah about six years when the
first November 30th 2022 yeah so there
was a lot of work leading up to that and
2022 launched today it has over 500
million people who talk to it on a
weekly basis. Yeah. I mean, people
All right. All right. So, um, by the
way, uh, get ready for some audience
questions because that's what that was
Sam's request. Um, you've been here for
three every single one of the ascents as
Pat mentioned and there's been some lots
of ups and downs, but seems like the
last six months it's just been shipping,
shipping, shipping. you shipped a lot of
thought stuff and it's amazing to see
the product velocity, the shipping
velocity continue to increase. So this
is like multi- sort of part question.
How have you gotten a large company to
like increase product velocity over
time? I I I think a mistake that a lot
of companies make is they get big and
they don't do any they don't do more
things. So they just like get bigger
because you're supposed to get bigger
and they still ship the same amount of
product and that's when like the
molasses really takes hold. I I like I
am a big believer that you want everyone
to be busy. You want teams to be small.
You want like to do a lot of things
relative to the number of people you
have. Otherwise, you just have like 40
people in every meeting and huge fights
over who gets like what tiny part of the
product. Um there there was that there
was this like old observation of
business that like a a a good executive
is a busy executive because you don't
people like muddling around. Um
but I I think it's like a good
I you know at our company and many other
companies like researchers, engineers,
product people, they drive almost all
the value and you want those people to
be busy and high impact. So if you're
going to grow, you better do a lot more
things otherwise you kind of just have a
lot of people sitting in your room
fighting or meeting or talking about
whatever. Um so we try to have you know
relatively small numbers of people with
huge amounts of responsibility. Um and
the way to make that work is to do a lot
of things.
And also like we have to do a lot of
things like that the to go kind of I
think I think we we really do now have
an opportunity to go build one of these
important internet platforms. Um but to
do that like if we really are going to
be people's like personalized AI that
they use across many different services
and you know over their life and across
all of these
different all these different like kind
of main categories and all the smaller
ones that we need to uh figure out how
to enable then that's just a lot of
stuff to go build. Anything you're
particularly proud of that you've
launched in the last six months?
I mean, the models are so good now.
Like, they they still have areas to get
better, of course, and we're working on
that fast, but
like I think at this point, Chad GBT is
a very good product because the model's
very good. I mean, there's other stuff
that matters, too, but the I am like I'm
amazed that one model can do so many
things so well. You're building small
models and large models. You're doing a
lot of things as you said. So, how do
this audience stay out of uh your ways
and not be roadkill?
Um, I mean, like I I I think the way to
model us is we want to build we want to
be people's like core AI subscription
and way to use that thing. Some of that
will be like what you do inside of Chad
GPT.
Um, we'll have a couple of other kind of
like really key parts of that
subscription.
But
mostly we will hopefully build this
smarter and smarter model. We'll have
these surfaces
like future devices, future things that
are sort of similar to operating
systems, whatever. Um, and then you know
we want we have not yet figured out
exactly I think what the sort of
API or SDK or whatever you want to call
it is to like really be our platform.
But we will. It may take us a few tries,
but we will. Um, and I hope that that
enables like just an unbelievable amount
of wealth creation in the world and
other people to build onto that. But
yeah, we're going to go for like the
core AI subscription and the model and
then um the kind of core services and
there will be a ton of other stuff to
build. Okay. So, don't be the Core AI
subscription, but you can do everything
else.
We're going to try. I mean, if you can
make a better Corei subscription
offering than us, go ahead. That'd be
great. Okay. Um, it's rumored that
you're raising $40 billion or something
like that at $340 billion valuation.
It's rumors that it's I don't know if I
think we announced it. We're okay. Well,
if I just want to make sure that you
announced it. Um, what's the what's your
scale of ambition from there? From here,
we're going to like try to make great
models and ship good products and
there's no master plan beyond that. Like
we're gonna I I I think like Sure. No, I
I I I mean there's I see plenty of open
eye people in the audience. They can
vouch for that. Like we don't we don't
sit there and have like I I am a big
believer that you can kind of like do
the things in front of you, but if you
like try to work backwards from like
kind of we have this crazy complex
thing.
Um that doesn't usually work as well.
Like the the we we know that we need
tons of AI infrastructure. like we know
we need to go build out massive amounts
of like AI factory volume. Um we know
that we need to keep making models
better. We know that we need to like
build a great top of the stack like kind
of consumer product and all the pieces
that go into that.
But we pride ourselves on being like
nimble and adjusting tactics as the
world adjusts. And so the products
um you know the products that we're
going to build next year we're probably
not even thinking about right now.
And we believe we can build uh a set of
products that people really really love.
Um and we have like unwavering
confidence in that and we believe we can
build great models. I' I've actually
never felt more optimistic about our
research road map than I do right now.
Um what's on the research road map?
Really smart models.
Um but but in terms of like the steps in
front of us, we kind of take those one
or two at a time. So you believe in
working forwards, not necessarily
working backwards. I have heard some
people talk about these brilliant
strategies of how they're this is where
they're going to go and they're going to
work backwards and you know this is take
over the world and this is the thing
before that and this is that and this is
that and this is that and this is that
and here's where we are today. I have
never seen those people like really
massively succeed. Got it. Who who has a
question? There's a mic coming your way
being thrown.
Um, what do you think the larger
companies are getting wrong about
transforming their organizations to be
more AI native in terms of both using
the tooling as well as producing
products? It's been, you know, it's
smaller companies are clearly just
beating the crap out of out of larger
ones when it comes to innovation
here. I I think this basically happens
every major tech revolution. Um, there's
nothing to me surprising about it. The
thing that they're getting wrong is the
same thing they always get wrong, which
is like people get incredibly stuck in
their ways. Organizations get incredibly
stuck in their ways. If things are
changing a lot every quarter or two and
you have
like an information security council
that meets once a year to decide what
applications you're going to allow and
what it means to like put data into a
system, like it it's just it's so
painful to watch what happens here. But
like, you know, this is this is creative
destruction. This is why startups win.
this is like how the industry moves
forward. Um I am I'd say I feel like
disappointed but not surprised at the
rate that big companies are willing to
do this. Um they
will my kind of prediction would be that
there's another like couple of years of
fighting pretending like this isn't
going to reshape everything and then
there's like a capitulation and a last
minute scramble and it's sort of too
late and in general startups just sort
of like blow past people doing it the
old way. Um, I mean this happens to
people too like
watching watching like
a you know someone who
started maybe you like talk to an
average 20-year-old and watch how they
use chat GBT and then you go talk to
like an average 35-year-old and how they
they use it or some other service and
like the difference is unbelievable. It
reminds me of like, you know, when the
smartphone came out and like every kid
was able to use it super well and older
people just like took like three years
to figure out how to do basic stuff. And
then of course people integrate, but but
the the sort of like generational divide
on AI tools right now is crazy and I
think companies are just another symptom
of that.
Anybody else have a question?
Just to follow up on that, um, what are
the cool use cases that you're seeing
young people using with Touch EPT that
might surprise us?
They really do use it like an operating
system.
um they have like complex ways to set it
up to connect it to like a bunch of
files and they have like fairly complex
prompts memorized in their head or like
you know in something where they paste
in and out and um
the I mean that stuff I think is all
cool and impressive and there's this
other thing where like they don't really
make life decisions without asking like
chbt what they should do. Um, and it has
like the full context on every person in
their life and what they've talked about
and you know that like the memory thing
has been a real change there. But but
yeah, I
think gross oversimplification, but like
older people use Chachi PT as a Google
replacement. Maybe people in their 20s
and 30s use it as like
a life advisor something and then like
people in college use it as an operating
system.
How do you use it inside of OpenAI?
Um, I mean it writes a lot of our code.
How much? I don't know the number. And
also when people say the number I think
is always this very dumb thing cuz like
you said Microsoft code is 30 20 30%
written measuring by lines of code is
just such an insane way to like I don't
I I maybe the meaningful thing I could
maybe the thing I could say is it's
writing meaningful code like it's
writing I don't know how much but it's
like writing the the the parts that
actually matter. That's That's
interesting. Next question. Hey Sam, mic
going away. Is this okay? Hey, Sam. Uh,
I thought it was interesting that
the answer to Alfred's question about
where you guys want to go is focus
mostly around consumer and being the
core subscription and also most of your
revenue comes from consumer
subscriptions. Why keep the API in 10
years? I really hope that all of this
merges into one thing. like you should
be able to sign in with OpenAI to other
services. Other services should have an
incredible SDK to like take over the
chat GBT um UI at some point. But like
to the degree that you are going to have
a personalized AI that knows you, that
has your information, that knows what
you want to share later, and you know
has all this context on you, you'll want
to be able to use that in a lot of
places. Now, I agree that the current
version of the API is very far off that
vision, but I think we can get there.
Uh yeah, I maybe have a follow-up
question to that one. You kind of took
mine. Um but like a lot of us who are
building application layer companies, we
want to like use those building blocks,
those different API components, maybe
the deep research API which is not a
release thing but could be uh and and
build stuff with them like is that going
to be a priority like enabling that
platform for us? How should we think
about that? Yeah,
I I think I hope something in between
those that there is sort of like a new
protocol on the level of HTTP for the
future of the internet where things get
federated and broken down into like much
smaller components and agents are like
constantly exposing and using different
tools and authentication, payment, data
transfer, it's all like built in at this
level that everybody trusts. everything
talk to everything.
And I I don't quite think we know what
that looks like, but it's like coming
out of the fog. Um, and as we get a
better sense for that, again, it'll
probably take us like a few iterations
toward that to get there. But that's
kind of where I would like to see things
go.
Hey, Sam. Uh, back here. Uh, my name is
Roy. I'm curious, uh, the AI would
obviously do better with more input
data. Is there any thought to feeding
sensor data, uh, and what type of sensor
data, whether it's temperature, uh, you
know, things in the physical world that
you could feed in that it could better
understand reality. People do that a
lot. uh people like put that into you
know people have whatever they build
things where they just put sensor data
into like an API and like an 03 API call
or whatever and for some use cases it
does work super well. Um I'd say that
the latest models seem to do a good job
with this and they used to not. Uh so
we'll probably bake it in more
explicitly at some point but there's
already like a lot happening there.
Hi Sam. Uh I was really excited to play
with the voice model in the playground
and so I have two questions. The first
is how important uh is voice to open AAI
in terms of like stack ranking for
infrastructure and can you share a
little bit about how you think it'll
show up in the product and chat GBT the
core thing.
I think voice is extremely important.
Honestly, we just we have not made a
good enough voice product yet. That's
fine. Like it took us a while to make a
good enough text model too. Um, we will
crack that code eventually and when we
do, um, I think a lot of people are
going to want to use voice interaction a
lot more. I I am super when we first
launched our current voice mode, the
thing that was most interesting to me
was it was a new stream on top of like
the touch interface and I you could talk
and be like clicking around on your
phone at the same time. And I continue
to think there's something amazing to do
about like voice plus guey interaction
that we have not cracked. But before
that, we'll just make voice really
great. And when we do, I think there's a
not only is it cool with existing
devices, but I I sort of think voice
will enable a totally new class of
devices if you can make it feel like
truly human level voice.
Similar question. Similar question about
coding. I'm curious, is coding just
another vertical application or is it
more central to the future of open AI?
That one's more central to the future of
open AI. Um, coding I think will be
how these
models kind
of right now if you ask CHP a response,
you get text back, maybe you get an
image. Um, you would like to get a whole
program back. You would like, you know,
custom rendered code for every response
or at least I would. um you would like
the ability for these models to go make
things happen in the world and writing
code I think will be very central to how
you like actuate the world and call a
bunch of APIs or whatever. So I I would
say coding will be more
in a central category. We'll obviously
expose it through our API on our
platform as well. Um but you know chat
GBT should be excellent at writing code.
So we're going to move from the world of
assistants to agents to basically
applications all the way through.
I I I think it'll feel yeah like very
continuous but yes
u so you have conviction in the road map
about smarter models awesome I have this
mental model there's some ingredients
like more data bigger data centers a
transformer architecture test time
compute what's like an underrated
ingredient or something that's going to
be part of that mix that like maybe
isn't in the mental model of most of
Um, I mean that's kind of the each of
those things are really hard and you
know obviously
like the highest leverage thing is still
big algorithmic breakthroughs and I
think there still probably are some 10
x's or 100 x's left not very many but
even one or two is a big deal.
Um but you know yeah it's kind of like
algorithms, data, compute those are sort
of the big ingredients.
Uh
hi uh so my question is you run one of
the best ML teams in the world. Uh, how
do you balance between uh letting smart
people like Issa chase uh deeply
research or something else that seems
exciting versus going top down and being
like we're going to build this, we're
going to make it happen. We don't know
if it'll work. There are some projects
that require so much coordination that
there has to be a little bit of like top
down quarterbacking, but I think most
people try to do way too much of that.
I I I mean this is like there's probably
other ways to run good AI research or
good research labs in general, but when
we started OpenAI, we spent a lot of
time trying to understand
uh what a well-run research lab looks
like. And you had to go really far back
in the past. In fact, almost everyone
that could like help advise us on this
was dead. Um it had been like a long
time since there had been good good
research labs.
And you know people ask us a lot like
why why does open AI like repeatedly
innovate and why do the other AI labs
like sort of copy or why do like biolab
x not do good work and biolab y does do
good work or whatever. And we sort of
keep saying like here's the principles
we've observed. Here's how we learned
them. Here's what we looked at in the
past. And then everybody says great um
but I'm going to go do the other thing.
We said that's fine. Like you came to us
for advice. Like you do what you want.
Um but I find it remarkable how much
these few principles that we've tried to
run our research lab on which we did not
invent. We shamelessly copied from other
good research labs in history um have
worked for us. And then people who have
had some smart reason about why they
were going to do something else, it
didn't work.
Um, so it seems to me that uh these
large models uh one of the really
fascinating things as like a lover of
knowledge about them is that they
potentially embody and allow us to
answer these like amazing long-standing
questions in the humanities about
cyclical changes and artistic uh
interesting things or even like uh you
know to what extent systematic prejudice
and other sorts of things are really
happening in society and can we sort of
detect these and I'm uh very subtle
things which we we could never really do
more than hypothesize before. And I'm
wondering whether OpenAI has a thought
about or even a roadmap for working with
academic researchers say to help unlock
some of these new things we could learn
for the first time in the humanities and
in the social sciences. We do um yeah I
mean it's amazing to see what people are
doing there. We do have academic
research programs where we partner and
you know do some custom work but mostly
people just say like I want access to
the model or maybe I want access to the
base model and I think we're really good
at that. Uh one of the kind of cool
things about what we do is so much of
our incentive structure is pushed
towards making the models as smart and
cheap and widely accessible as possible
that that serves academics and the
really the whole world very well. So,
you know, we we have we do some custom
partnerships, but we often find that
what researchers or users really want is
just for us to make the general model
better across the board. Um, and so we
we try to focus, you know, kind of 90%
of our thrust vector on that.
I'm curious how you're thinking about
customization. So, you mentioned the
federated like sign in with OpenAI,
bringing your memories, your context.
I'm just curious if you think
customization and like these different
post- training on like application
specific things is a band-aid for or
trying to make the core models better
and how you're thinking about that.
I mean in some sense I think the like
platonic ideal state is uh a very tiny
reasoning model with a trillion tokens
of context that you put your whole life
into. The model never retrains. The
weights never customize. But that thing
can like reason across your whole
context and do it efficiently. And every
conversation you've ever had in your
life, every book you've ever read, every
email you've ever read, um, every
everything you've ever looked at is in
there, plus connected all your data from
other sources. And, you know, your life
just keeps appending to the context and
your company just does the same thing
for all your company's data. Um, we
can't get there today. Uh but but I I
think of kind of like anything else as a
a compromise off that platonic ideal and
that is how I would eventually I hope we
do customization. One last question in
the back. Hi Sam, thanks for your time.
Where do you think most of the value
creation we come from in the next 12
months? Would it be maybe advanced
memory capabilities or maybe security or
protocols that allow agents to do more
stuff and interact with the real world?
Um I mean in some sense the value will
continue to come from really three
things like building out more
infrastructure, smarter models
and building the kind of scaffolding to
integrate this stuff into society. And
if you push on those, I think the rest
will sort itself out. Um, at at a higher
level of
detail, I kind of think 2025 will be a
year of sort of agents doing work.
Coding in particular, I would expect to
be a dominant category. I think there'll
be a few others too. Um, next year is a
year where I would expect more like
uh sort of AI discovering new stuff and
maybe we have AIs make some very large
scientific discoveries or assist humans
in doing that. And you know, I'm I am
kind of a believer that most of the sort
of real sustainable economic growth in
human history comes from once you've
like kind of spread out and colonized
the earth, most of it comes from just
better scientific knowledge and and then
implementing that for the world. And
then 27 I I would guess is the year
where like that all moves from the sort
of intellectual realm to the physical
world and robots go from a curiosity to
like a serious economic creator of
value. But that was like an off the top
of my head kind of guess right now. Can
I close with a few quick questions?
Great. One of which is um chat uh GPT5.
Is that going to be just all smarter
than all of us here?
Um I mean if you think you're like way
smarter than 03 then maybe you have a
little bit of a ways to go but 03 is
already pretty smart.
Um two personal questions. Last time you
were here, you had just come off a blip
with open AI. Uh given some perspective
now in distance, you got any advice for
founders here about resilience,
endurance,
strength?
Um it gets easier over time. I think
like you will face a lot of adversity in
your journey as a founder
and the the kind of challenges get
harder and higher stakes but the
emotional toll gets easier as you kind
of go through more bad things. So it's
uh you know in some sense
like it does it yeah even though like
abstractly the challenges get bigger and
harder the your ability to deal with
them the sort of resilience you build up
gets easier like with each one you you
kind of go through.
Um and then I like I I think the the
hardest thing about the big challenges
that come as a founder is not the moment
when they happen. Uh like a lot of
things go wrong in the history of a
company.
Um in the acute thing you can kind of
like you know you get a lot of support,
you can function a lot of adrenaline.
like that's, you know, you're kind of
like e even the really big stuff like
your company runs out of money and
fails, like a lot of people will come
and support you. Um, and you kind of get
through it and go on to the new thing.
The thing that I think is harder to sort
of manage your own psychology through is
the sort of like fallout after. Um, and
I think if there's, you know, people
focus a lot about how to work in that
one moment during the crisis. And the
really valuable thing to learn is how
you like pick up the pieces. There's
much less talk about that. I think
there's I've never actually found
something good to point founders to to
go read about, you know, not how you
deal with the real crisis on day zero or
day one or day two, but on day 60 as
you're just trying to like rebuild after
it. Um, and that's that's the area that
I think you can like practice and get
better at. Thank you, Sam. Yeah, you're
officially still on paternity leave. I
know. So, thank you for coming in and
speaking with us. Appreciate it. Thank you.
