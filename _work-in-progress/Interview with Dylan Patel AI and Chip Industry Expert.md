# AI and Chip Industry Discussion - Dylan Patel Interview

**Guest:** Dylan Patel (AI and Chip Industry Expert)
**Host:** [Host Name]
**Video URL:** https://www.youtube.com/watch?v=cHgCbDWejIs&t=1863s
**Video ID:** cHgCbDWejIs
**Transcript extracted and cleaned on:** 2025-07-05

---

## Executive Summary

This interview features Dylan Patel, a leading expert in AI and the chip industry who provides insights into the current state and future of artificial intelligence, semiconductor technology, and the competitive landscape between major AI companies.

---

## Main Conversation


**[00:00]** Super intelligence reaching it first.


**[00:01]** Who are you picking and why? Open AAI.


**[00:05]** He's the guy the chip industry reads before making a move. Meet Dylan Patel.


**[00:10]** He's a quick thinker with a depth and breath of knowledge that is unrivaled in AI. You know, for one, scale AI is like.


**[00:19]** It's kind of cooked. And today, Dylan's answering the tough questions. What went wrong with GPT 4.5? In general, it's not.


**[00:26]** That useful and it's too slow. You zoom back, right? It's if you believe super intelligence is the only thing.

That matters, then you need to chase it. 

Otherwise, you're a loser. It's not the money, it's more the power. What do you think is going on at Apple? They hate. Nvidia. Maybe for reasonable reasons. Models are just pansies about like giving me data. You're using 03 dayto-day even though there's, you know,. 

It takes so much time to actually get your response back. The model I go to the most is either 50% of white collar. Jobs could disappear. Generally, people work less than ever before. The average amount of hours worked 50 years ago was. Way higher. And then eventually like there just won't be humans in the loop, right? And eventually you believe. 

That it's an art form to some extent. What is worth researching and what's not? GPUs that ended up breaking. It was called bumpgate. It was a very. Interesting thing. Um you don't or you do. No, I don't. Oh, so okay. So this is a very fun story, right? 

All right, Dylan, thank you so much for joining me today. Really excited to talk to you. I've seen you do a number of. Talks. I've seen you do a number of interviews. We're going to talk about a whole bunch of things. So first thing I. Want to talk about is meta. Let's start with Llama 4. I know it's been a little while in the AI world since that kind of. 

Released, but there was a ton of anticipation. It was good, not great. It wasn't kind of world changing at the. Moment. Um, and then they delayed Behemoth. What do you think is going on there? Yeah. So, I mean, it's funny. There's three different models and they're all quite different. So, Behemoth got delayed. Uh, I actually. 

Think they might not ever release it. I'm not sure. There's a lot of problems with it. the way they trained it, some of the decisions they made don't pan. Out. And then there's Maverick and Scout, right? Um, and so one of those models is actually decent. It's pretty. 

Good. It wasn't the best on release, but it was it was comparable to the best Chinese model on release, but then, you. Know, Alibaba came out with a new model. Deepseek came out with a new model, so I was like, "Okay, it's worse." Uh, the other one was objectively just bad. I. 

Know for a fact they they trained it as a response to DeepSeek, trying to use more of the elements of Deepseek's. Architecture, but they didn't they didn't do it properly. it was just a rush job and it really messed up um. Because they went really hard on the uh on the sparity on thee. But funnily enough, if you actually look. 

At the model, it often times won't even route tokens to the certain experts. So it was a waste of training. Basically within in between every layer the router can route to whatever expert it wants to and it learns which expert to route to and. And each expert learns its own independent things and it's really not something observable by people but. 

What you can see is tokens when which experts do they route to or you know when when they when they go through. The model and it's just some of them just didn't get routed to. So it's like you have a bunch of empty experts. That are not doing stuff. So there's clearly something wrong with training. 

Is it an expertise thing internally? I mean, they have to have some of the best people in the world,. And we're going to get to some of their hiring efforts as of late, but what what why why haven't they been able. To really do it? I think it's a combination and confluence of things, right? Like yes, they have tons of. 

Talent. They have tons of compute, but the organization of people is always like the most challenging thing. Which. Ideas are actually the best? Who's the technical leader choosing the best ideas? Right? It's if you have a. Bunch of great researchers that's awesome but then if you put product managers on top of them and then there's. 

No technical lead who's evaluating what to choose then you have a lot of problems right open AI right yeah Sam is. A great leader and he gets all the resources but the technical leader is Greg Brockman right and Greg Brockman is. Choosing a lot of stuff and there's a lot of other folks right Mark Chen and others who are the technical. 

Leaders who are really deciding the like technically which route do we go down because a researcher is going. To have their research, they're going to think their research is the best. Who's evaluating everyone's research and then. Deciding that idea is great, let's use that one. That one sucks. Let's not use that one. It's just really difficult. 

So, when you end up with researchers not having a leader who is technical and can choose and and really, you know,. Choose the right things, you end up with great, we did have all the right ideas. Um, but part of AI research is that you have all the wrong ideas too and you learn from them and you have the right. 

Ideas and you choose them, right? And now what if what happens if your choosing of them is really bad and. Actually you choose some wrong ideas and then you go up the, you know, the branch of sort of research, right? Like you've. Chosen this bad idea. This is something we're going to do. Let's go further down. And then now you're like, oh,. 

Branching off of this bad idea, there's a lot more research because, you know, it's like, well, we're not going to go. Back and undo the decision we made, right? Right? So everyone's like, "Oh, we made that decision. Okay, let's see. What's researchable from here." And so you end up with this like potentiality of great researchers wasting their time on bad paths, right? 


**[05:01]** And and there's sort of this thing that researchers talk about which is taste, right? Which is very funny,.


**[05:07]** Right? You think these are like these are nerds who won the International Math Olympiad and like that's their like, you know, claim to.


**[05:14]** Fame when they were a teenager and then they got a job at OpenAI or whatever at 19 or a meta or whatever.


**[05:20]** But there's actually a lot of taste involved, right? It's it's it's it's an art form to some extent. What is what.


**[05:26]** Is worth researching and what's not and it's an art form of choosing what's the best because you're making all these.

Ideas down here on the scale here and then all of a sudden you're yeah let's now great those experiments were all done with 100. 

GPUs. Awesome. Now let's make a run with 100,000 GPUs with that idea. It's like well things don't just translate. Perfectly. So there's a lot of taste and intuition here. It's not that they don't have good researchers. It's that like. Who's choosing the taste, right? Is is difficult, right? Like, you know, it's like you don't care about movie critic. 

Reviews, you care about Rotten Tomatoes, you know, audience score perhaps, right? And it's it's who's the critic that you're listening to, though, right? And that's that's it's it's challenging to even if you have great people to actually have good stuff come. 

Out because of organizational issues because the right people aren't at the right spot and decision makers and maybe. The wrong person gets to be political and have their idea and research path put into the model when it's not necessarily a good idea. Yeah. And okay well let's continue down the path of who is making decisions. 

Obviously Zuck last week there was a lot of news about him giving a hund00 million offers. Sam Alman. Literally said it. They acquired Scale AI seemingly for Alexander Wang and his team. He's in founder mode. What does. The Scale AI acquisition actually give Meta first? Let's start there. Yeah. So I think for one scale AI is. 

Like it's kind of cooked right now as a company as a company because everybody's cancelling their Google Google's backing. Out. I think they're going to spend on the order I've heard $250 million this year with them and they're backing. Out. Obviously, they've spent a lot of money. There's stuff they can't back out of. But it's that's going to go. 

Down a lot, right? Open AAI allegedly like cut the external Slack connection, right? So there's no slack between. Scale and open AAI anymore. So obviously that ultimate breakup between companies. Yeah. So obviously these companies like I don't want Meta to know what I'm doing, right, with my data because. 

That's one of the unique aspects of models is what do you what do you want with your custom data? Um so. Clearly scale is not Meta didn't buy scale for scale right they bought scale for the purposes of having. Alex and his few best colleagues the there's a few other folks at at at scale who are really awesome as well and and. 

They bought them they bought them to bring them over right now the question is sort of is the data that scale has good is is all knowing. All the paths of sort of data labeling that all these other companies were doing good Sure. Um, but more. Importantly, it's we want to get, you know, someone to help us lead this super intelligence effort, right? And. 

And Alex is a uh, you know, he's he's same age as me. He's 28 or 29ish yet. I think he's he's pretty he's around that. Age. Stupendously successful in every way, shape, or form, right? People can hate on him if they want, but he's. Obviously very successful, especially when he convinces Mark Zuckerberg, who's not an irrational person, he's very. 

Smart, to buy his company, right? like you know it's and there his company was doing nearly a billion of. Revenue and is let's chase super intelligence right which is very different right if you go look at Zuckerberg's interviews even a handful. Of months ago he wasn't chasing super intelligence right he was chasing like AI is good and great but AGI is not. 

A thing that is going to happen soon um so sort of this is a big shift in strategy in that he's basically. Saying yeah yeah super intelligence is all that matters we're on the path there I believe now what can I do to get. Catch up cuz I'm behind It seems like the narrative throughout all of these major companies is now super. 

Intelligence even when it was AGI just a month ago. What it why the transition by the way? The word AGI has no meaning. Anymore. Amorph is Yeah. Right. It's like it's you can look at an anthropic researcher in the face and be. Like what does AGI mean? And they literally think it just means an automated software developer. And it's. 

Like that's not artificial general intelligence but that's what they think right. and a lot of researchers. Across the ecosystem. Ilia saw this, you know, Ilia saw everything first, obviously, Ilia Suster. Um, and he. Started his company, Safe Super Intelligence, right? SSI, and I think that started the rebranding. And now,. 

Like, you know, many months later, it's like almost a year now. A year later, um, I think it's nine months to a. Year later, you know, everyone's like, "Oh, super intelligence is a thing." So, another another research direction,. Right, that Ilia got first, right? 

Whether it was whether it was like pre-training scaling or uh, you know, the original vision networks,. Right? pre-training, scaling, reasoning, right? All these things that he sort of had the idea at least if not first among. The first and and worked on it a lot. 

Um you know, sort of Ilia's got this one too, which is the rebranding. So maybe he's got marketing, too. Yeah. Well,. Zuck, I at least rumored tried to acquire SSI and was rebuffed by Ilia, right? And then I wanted to also ask. 
**[10:08]** You about Daniel Gross and Nat Freeman.


**[10:10]** Think it's rumors maybe confirmed at this point but seems Zuck is trying to hire them as well. What did those two.


**[10:15]** Folks give Zuck? Zuck tried to buy SSI.


**[10:18]** He also tried to buy Thinking Machines.


**[10:20]** Like these are rumors. He also tried to buy Perplexity. These are all in some of the media, right? He tried to buy all.


**[10:25]** These companies, but specifically like some of the rumors that have been floated around is basically that like.

Mark tried to buy SSI. Ilia obviously said no because he is committed to super intelligence and straightshotting. 

It, right? Not worried on products and he's probably not even that money focused, right? He's mostly focused on. Like building it, right? Um a true believer in all all respects and regards, right? Um so obviously he. Probably was no. Um I don't know what the makeup of equity is there, but Ilia's Ilia's probably got strong enough. 

Votership and ownership to be no. Um, and if the rumors are true about Daniel Gross, then Daniel Gross probably was the one wanting the. Acquisition, right? He's like, "Yeah, this is awesome." Yeah. Another founder. 

Um and he comes from not an AI research background although he's is he's technical to some to a degree. But it's he you know he had his venture fund with NAT and he then he founded SSI with Ilia and he probably wanted the acquisition and and. And then it's well I was pushing for an acquisition and it didn't happen and you know I'm just guessing he. 

He's he's probably if he if he's going at all I don't actually know if he's going at all. Um it would make sense. That that's a chasm and split and he's going and I think I think generally when you look at really uh a lot of people who are very. Successful it's not the money right it's it is the money always but it's it's more the power right and if you. 

Ask anyone going to meta a lot of them will obviously be going for money but a lot of them are going. Because now they have control over uh the AI path for, you know, a trillion dollar plus company and they're right. There talking to Zuck u and they can convince one person who has full voting rights over the entire company, right? 

It's there's a lot of power there, right? And they can implement across billions of users, right? Whatever AI. Technology they want using the engine of Facebook, whether it be infrastructure or researchers or product to push. Whatever AI product you want, right? And that that would make a lot of sense to me for an Alex Wang or a. 

Mark Zucker or for a for a Nat Friedman or a Daniel Gross who are they are much more product people right Nat. Doing GitHub co-pilot he's a product person right he's not an AI researcher although he knows a lot about. AI researcher he's a he's a product person right and and same applies to sort of Alex obviously he's. 

He's very well verssed with the research but his super skill set is is product and people and convincing people. And organization probably not as much the research. That's sort of the the angle there is they've got they've. Got all this power to do a lot at Meta. Sam Alman also mentioned that Meta has been giving $100 million bonus. 

Offers to their top researchers. Apparently none of the top researchers have left. I I want to ask is is that a successful strategy just to throw. Money at the problem, get the best people in? It feels maybe the the cultural element would be lacking there. 

Where give as much as you want to open AI and Sam Alman but they like there are a lot of true believers. There in what they're doing. Is that enough to just throw money and get the best researchers where that culture is. Going to be built? you zoom back, right? 

It's if you believe super intelligence is the only thing that matters, then you need to chase it. Otherwise, you're a loser, right? And Mark Zuckerberg certainly doesn't want to be a loser and he thinks he can build. It. He can build super intelligence too, right? So then question is like, okay, well, what do you do? Well, then you go. 

And try and acquire the best teams out there, right? Thinking machines, right? All these ex OpenAI people, but also there's some other folks from, you know, Character AI, GDM, Meta, etc., right? All these great researchers and and infra people. And same with SSI, right? 

It's Ilia and the people he's recruited. Um, you know, trying to recruit people from these companies, uh, or try and buy these companies. That didn't work out. Um, so now you go with Alex who's like tremendously connected and can help you build the team and now you got. 

To go get the team right now. What's the difference between acquiring SSI where there's way less than 100. Employees, right? You know, I think I think there's less than even 50 employees at SSI and for for $30 billion. And and okay, well, you just paid hundreds of millions of dollars per researcher and 10 billion plus. 

For Ilia, right? Like that's sort of what you just did. And it's well then you're sort of doing the same. Thing, right? As far as Sam is saying that no top researchers have gone, I don't believe that's accurate. Um I. Think I think initially the top researchers definitely did say no. the best researchers, the best people. Um,. 


**[15:03]** And and you said hundred million dollars. I've I've heard a number for someone over a billion actually, uh, for.


**[15:08]** One person at OpenAI. Um, but anyways, you know, that's it's a ridiculous amount of money, but it's like, well,.


**[15:14]** It's the same thing as buying one of these companies, right? Thinking machines and SSI don't have a product.


**[15:18]** You're buying them for the people. If you know, super intelligence is the end all beall, $und00 million, even a.


**[15:24]** Billion dollars is really a drop in the bucket compared to one Meta market cap currently. and also the total.

Addressable market of artificial intelligence. I want to talk about Microsoft and OpenAI's relationship a. 

Little bit. We're well past the honeymoon phase, it seems. It definitely seems to be kind of the choppy waters of. Their relationship now. It's clear that open this is now a therapy show. Yeah, absolutely. Tell me about your feelings,. Sam and Satcha. Well, this is therapy, right? These are two people and they have a relationship and it does seem to. 

Be folding a bit. OpenAI's ambitions seem to have no bounds. Is Microsoft thinking right now? They they want to. Restructure the deal. OpenAI does Microsoft really has no reason to. But like what do you think is going on at. Like what do you think about the dynamics of this relationship going forward? Like Open I would not be where. 

They are without Microsoft and and Microsoft signed a deal where they get tremendous power. It's a weird ass deal because. Like open wanted to be a nonprofit and they cared about AGI but at the same time they had to give up a lot to get. The money. Uh, but at the same time, Microsoft didn't want to run into antitrust stuff, so they structured. 

This deal really weird, right? Which is like there's revenue shares and there's profit guarantees and. There's all these different things, but nowhere is it like, oh yeah, you own x% of the company, right? I think it's. Like they get I don't it's off the top of my head but I think it's 20% revenue share 49 or 51% profit. 

Share up until some cap and then there's like Microsoft has the IP rights of all of OpenAI IP until AGI right AGI and. It's all of these things are just like nebulous as hell right it's I think I think the profit cap might be. Like 10x again I'm going off the top of my head it's been a while since I looked at it but it's if if. 

Microsoft gave roughly $10 billion And OpenAI has it's it's a profit cap of 10x. It's well what incentive. Does Microsoft have to renegotiate now if they get a hundred billion dollars of profit from OpenAI and until then OpenAI. Has to give them all their profit or or half of their profit right and they get this 20% rev share and they have access. 

To all of OpenAI's IP until AGI but like what is the definition of AGI? Like theoretically, MC OpenI's board gets to. Decide when OpenAI hits AGI, but then if that happens, Microsoft will just shoot the sue the out of them. Um, and. Microsoft has more lawyers than God. Um, so it's it's this just like crazy ass deal. I think there's. 

Like a few really worrisome things in there for OpenAI. It's one of the main things they got ex removed. Already because Microsoft was really scared I think about antitrust aspects of this which was that OpenAI had to. Exclusively use Microsoft for compute. 

Um that that they backed off of this last year and it got announced with the Stargate deal this year, right? Which was that OpenAI is going to go to Oracle and SoftBank and Crusoe and the Middle East to build their. Stargate clusters, right? Their next generation data centers. They're still getting a bunch from Microsoft, of. 

Course, but a bunch from Stargate. And so, you know, or from Oracle primarily, but the others as well. Whereas before it was that openey could not do that without going directly to Microsoft right open tried to go to core. 

Initially but then Microsoft sort of inserted themselves in the relationship like no you're exclusively using us so a. Lot of GPUs get rented from core to Microsoft to open AAI but then this like exclusivity ended and now like. Coreweave has big deals signed with open AI and Oracle has big deals signed with open AI. What did Microsoft get in that. 

Exchange where they're going to give up the exclusivity? Did they get anything or was it reported that they got. Anything in exchange for that? Usually it's not just okay cool we'll give that up. What's been reported is just. That they gave up the exclusivity and in return all they have is a first writer refusal. Anytime OpenAI goes and tries. 

To get a contract for compute Microsoft can provide that same compute at the same price in the same time frame. Because reduce risk from from antitrust. Yeah. Like antitrust is one of the biggest considerations there, but there's other considerations of course,. 

But antitrust being one of the big ones cuz being the exclusive compute provider to OpenAI is a little. Little iffy. Um and and from OpenAI's perspective, they were just really annoyed that Microsoft was way slower. Than they needed them to be, right? They just couldn't get all the compute they needed. They couldn't get all the data. 

Center capacity, etc. Um Core Weave and Oracle are moving much faster. but even they are not as fast and so micro. Openai is turning to other folks as well right there's that butting of heads there but nowadays the real. 
**[20:02]** Challenging thing here is Microsoft has the monor repo it has the open AI IP they have rights to it all they can do.


**[20:10]** Whatever they want with it now whether it's Microsoft playing nice and not doing stuff with it or being.


**[20:16]** Somewhat incompetent and not being able to leverage it and mostly just like looking through it whatever the.


**[20:24]** Reason is Microsoft despite having access hasn't done a ton but the possibilities are endless right of.

What could be done then the other thing is if you're truly AGI or now super intelligence pill you have all the. IP up until SS super intelligence is is let's just say achieved but that would imply that the day before super. Intelligence is achieved you have all of the IP and then it gets cut off but you have all the IP up until right there so. 

It's one day of work maybe it's hard and it takes 10 days of work instead of one. Or maybe you achieve. Super intelligence, but it takes some time to get to the deliberations and agreement that you've achieved super. Intelligence slash all the evidence that you've achieved super intelligence, but like you've claimed it at this date, but. 

Like the model that is super intelligent is here you made it here. Open Microsoft has access to it, right? So. Sort of that's the real big risk or sort of to the super AGI pilled folks. the profit share and all this is very. Clean and difficult and most people don't care that much during when they're investing in OpenAI. It is challenging. 

To get every investor in the world to be like, "Yeah, your crazy ass structure, nonprofit, for-profit, all this sort of. Stuff." Okay, that's fine. Oh, Microsoft has rights to all of your profit for a long time and all your IP. So,. Theoretically, you could be worthless if they decide to just take some of your best researchers and implement. 

Everything themselves. Oh, wow. Right? Like these sorts of things scare investors and Sam said it himself, OpenAI is going to be the most capital. Intensive startup in the history of humanity. Yeah. Right. Um the valuation is going to keep soaring because what. 

They're building. OpenAI has no plans to produce profit anytime soon. They've been around for so long and they're. Doing $10 billion of revenue and they're still not going to do profit for another five years. And and by then. Their projections of pro of revenue are like well north of like there are hundreds of billions if not trillion. 

Dollars, right, of revenue that they expect themselves to have before they ever turn a profit. And so that whole. Way through they're going to be losing money and they need to keep raising money and they need to be able to. Convince everyone who's an investor in the world. And these things are dirty, right? Like they're not they're. 

Not clean and easy to understand. Okay. So you talked a little bit about compute capacity and specifically with Azure being able to go to coreweave and and. Elsewhere. I want to talk specifically about 4.5 GPC 4.5. It was deprecated I believe last week. Um this was a a. 

Massive model much was it really? It wasn't it? Oh I don't know. I thought it was still available in chat. That's I. Was just curious. Oh maybe they just announced the deprecation but it was imminent. No it's still there but yeah. They announced it. Okay. Yeah. No no they they've talked about no use. 

There's very little usage of it so that makes sense. Was the model too big? Was it too costly to run? Was what went. Wrong with GPT4.5? Orion is as it was internally called u what they hoped would be GPT5. 

They made that bet in early 24, right? They started training it in early 24. It was a bet on full scale, right? Uh full scale pre-training, right? We're just going to take all the data. We're going to make this ridiculously big. Model and we're going to train it. It is much smarter than 40 and 4.1 to be completely clear. I've I've said it's. 

The first model to make me laugh like because it's actually funny. Um but in general it's not that useful and it's. Too slow and it's too expensive. Um versus other models right 03 is just better. They went pure on the. Pre-training scaling data doesn't scale right so they weren't able to get a ton of data. So without data scaling so fast. 

Right they have this model that's really really big trained on all this compute but you have this issue called. Overparameterization. Generally in machine learning if you build a neural network and you feed it some data. It will tend to memorize first and then it will generalize right i.e. It'll know that if I ever say the quick brown. 

Fox jumped over, it would just know the next token is always lazy. Right? It isn't until you've trained it on a lot. More data that it learns what quick brown fox even means, what lazy dog is, right? It doesn't it doesn't actually. Builds a world model. It generalizes um and to some extent GPD 4.5 Orion was so large that it was and so. 

Overparameterized that it did it memorized a lot. Like actually when it initially started training, I know. People at OpenAI were so excited that they were like, "Oh my god, it's already crushing the benchmarks." And we're. Barely into training because some of the checkpoints were just so good, right? 

Initially, but that's because it just memorized so much. Um, but then it stopped improving. It was just. Memorized for a long time and it didn't generalize. It finally did generalize, right? Because it was such a big. Complicated run, they actually had a bug in it for months, right? Uh during the training, right? training is like. 


**[25:02]** Like usually handful of months or less, right? And it's usually less. Um, and they had a bug in the training code for.


**[25:10]** A couple months that was a very tiny bug that was messing up the training. It's funny when they finally found it, it was it was.


**[25:17]** Like a bug within PyTorch that like OpenAI had had found and fixed and they submitted the patch, there's like.


**[25:23]** 20 people open who reacted to the bug re fix reaction with emojis right on GitHub. Another thing is they had.

To restart training from checkpoints a lot is so big so complicated so many things can go wrong right and so from an infrastructure. Perspective just corelling that many resources and putting them together and having it train and having it train. 

Stably was really really difficult but from another flip side it's just like even if the infrastructure and code and. Everything that was pristine you still have this problem of data you know you're you're you sort of um. Everyone points to the chinchilla paper uh from 22 I I think 2022 Google released a paper called chinchilla deepb. 

Mind u and what it basically said is like for a model what's the optimal ratio of parameters to tokens and this. Only applied to dense models with the exact architecture of chinchilla model um but it was oh if I have x. Flops I should have this many parameters this many tokens right it's a scaling law right obviously as you make it. 

Bigger and you apply more flops the model gets better but how much data should I add how much more parameters. Should I add Now obviously so so over time people's architectures change the exact observations of chinchilla aren't accurate right which. Is that roughly it's 20 tokens per parameter that you want of data that you're training versus parameters in the. 

Model roughly there's actually a curve and everything it's more complicated than that but that observation is not identical but. What what it is is that as you add compute you want to add more data and parameters at a certain ratio or along a. Certain curve of you know there's there's a formula basically and an ideal world and they didn't go there. 

Right they had to go to way more parameters versus tokens but this was all early 24 when they started training. Um all these trials tribulations they finally get there and I don't remember when they released 4.5 it was last year right yeah yeah but. They finally released the model you know many months after they start training after they finish training. 

Pre-training and then they try and do RL and all this stuff but in the meantime different teams at OpenAI figure out. Something magical which is the reasoning stuff the strawberry so it was it was While they've already invested all this,. While they're in process of training this massive model, they were they realize, okay, for a much lower cost, we. 

Can get so much more efficiency, so much higher quality out of a model because of reasoning. Yeah. And if you really like. Try and boil down reasoning to first principles, you're giving the model a lot more data. Where are you getting. This data from is you're generating it. 

And how are you generating the data? Well, you're creating these verifiable domains where the model generates data and you throw away all the data where it. Doesn't get to the right answer, right? 

Where it doesn't verify that that math problem or that code or that unit test was good. So in a sense it's kind of. Like you know looking backwards obviously I didn't have the intuition then but looking backwards the intuition makes a lot of. Sense that well 4.5 failed because it didn't have enough data also it was just very complicated and difficult on a. 

Scaling perspective infrastructure- wise um and there were tons of problems and challenges there but also it just. Didn't have enough data and now like this breakthrough that happened from a different team is generating more data. And that data is good right a lot of the synthetic data stuff is bad data but the the magic of strawberry of of reasoning is. 

That the data is good. The the data that you're generating. So it's it's it's really from a first principles. Basis makes a lot of sense that data is the wall. U just adding more parameters doesn't do anything. I want. To talk about Apple for a second. Um I'm sure you have some thoughts on that. 

Apple is clearly behind. We're not getting much in the way of public models, leaks, anything about knowing. What they're doing. What do you think is going on at Apple? Do you think they just made a misstep? they kind of were. Late to the game. Why aren't they acquiring companies? Like what what is happening internally if you had to. 

Guess? Yeah. So I think Apple is like very very conservative company. They've acquired companies in the past but they. Never done really big acquisitions. Beats was the biggest one as a headphone company, right? But generally their their acquisitions have been really. 

Small and they do buy a lot of companies. They just buy really really small companies early. They identify. It. Maybe it's a failing startup or it's you know whatever it is. They buy they buy these startups that haven't achieved. Product market fit and aren't super sexy. Like as far as Apple, they've always had problems attracting in terms. 

Of AI researchers, AI researchers like to blab. They to post and publish their research. Um, and Apple's always. Been a secretive company. They actually changed that policies to where their AI researchers are allowed to publish. Uh,. But at the end of the day, they're still a secretive company. Um, they're still like an old antiquated company. It's. 

Like Meta only was able to like hire a bunch of researchers and talent because they had a bunch of ML talent. 
**[30:02]** Already, right? They've always been a leader in AI. They had this PyTorch team as well. And then they're they committed.


**[30:08]** To open sourcing a lot for a while now.


**[30:10]** They've been open sourcing. Yeah.


**[30:12]** Besides that, who's been able to acquire AI talent? The Deep Mind to OpenAI shift, you know, open OpenAI.


**[30:17]** Being the rival to Deep Mind and like that whole thing and all a lot of great researchers coming together to.


**[30:22]** Form it. and then the anthropic splinter group and then thinking machine splinter group from open AAI and SSI's.


**[30:27]** Thinking splinter group from open AI right it's what companies have actually been able to acquire talent.

That didn't already have AI talents like Google deep mind is just the biggest name in the game and they've. 

Always had the highest inflows of AI researchers and PhDs and then there's like open AAI and anthropic who are sort. Of and and thinking machines and SSI right it's all open AI it's hard to get talent to come to you now anthropic has. Such a strong culture that they're able to get people. Open AI is being the leader. Uh Meta, you know, I sort of. 

Talked through it's how is Apple going to attract these best researchers? They're not right. They're going to get, you know, not the best researchers. Um and so it's it's really challenging for. Them to be competitive, right? And then there's the whole they have a stigma against they hate Nvidia. Um. 

And maybe for reasonable reasons. Um you know, Nvidia threatened to sue them over some patents in at one point. Um Nvidia sold them GPUs that ended up breaking. It was called Bumpgate. It was a very interesting thing. I don't. 

Remember that. Um you don't or you do? No, I don't. Oh. So, okay. So, this is a very fun story, right? One generation of Nvidia's GPUs. I'm I'm going to butcher. The exact reason because it's been a while since I ago was this. Uh this is like this is probably 2015, if not. 

Earlier. Um there's a generation of Nvidia GPUs for laptops, right? Um and and chips have solder balls on the. Bottom, right, that connect their IO pins to the motherboard and to the CPU, power, etc. Somewhere along the. Chain supply chain, all the companies Dell, HPE, Apple, Lenovo, they blamed Nvidia as far as I understand, but vice. 

Versa, Nvidia said it wasn't their fault. I'm not going to prescribe blame, but the solder balls would not like. They were not good enough, right? And so when the temperature is swung up and down, coefficient of thermal expansion, right, different materials. 

Expand and shrink at different rates, um the chip versus the solder balls versus the PCB would expand and shrink at. Different rates. And what ended up happening is because of that different rate of expansion, the solder. Balls connecting the chip and the board would crack. They would and it was called bumpgate. U and now the. 

Connection is severed, right? The connection between the chip and the board. And so it's called bumpgate. And. Um I think Apple wanted compensation from Nvidia. I think Nvidia was no. Uh there's this whole thing Apple really hates Nvidia because of that and because of this threatening when Nvidia. 

Was trying to get into mobile chips because they tried to get into mobile chips for a time period and they failed. Uh but at one point they tried to sue everyone over over GPU patents in mobile. Um and so between those two. Things, Apple really doesn't Nvidia and so Apple doesn't really buy much Nvidia hardware. They don't really need. 

To anymore. Well, they don't need to in the laptops, of course, but even in data centers, right? It's like, well,. Like again, if I'm a researcher, first of all, I'm going to go where the talent is, where I have my culture fit,. Where the money is. And even in places that have a ton of compute and good researchers, Meta still has to offer. 

Crazy money to get people to come over. It's Apple one is not going to offer that crazy money. And also, they don't even have compute. And then for. Inference to serve users, they run it on Mac chips and data centers. It's like very bizarre. And it's like, I don't. 

Want to deal with all that stuff. I want to build the best models, right? Like it's there's there's it's. Challenging for Apple. Okay. I I want to ask you one last question about Apple. They are very big on ondevice AI and and I actually really that approach security latency. Um what's your take on. 

Ondevice AI, pushing AI to the edge versus having it in the cloud? Is it somewhere in the middle? What do you. Think? So, so I think there's I'm I'm generally an ondevice AI bear. I don't it that much. Um like personally I think security is awesome. Um but I know human psychology free is better than free with ads is better than security. Um no one actually cares. 

About security they say they do but the number of people who actually make decisions based on security are very. Little. I would privacy and security of course. But wait but you said it's you free it but you're not you're not that's not. Analogous to ondevice AI right? No no no. So, so Meta will offer in the cloud for free and CH OpenAI has a free. 

Tier and so Google has a free tier and it's going to be better than free as in running it on your own. Device. Right. Right. And that's pro that's a big big challenge with that is that on device is that you're you're. Limited by the hardware. Right. Um and so how fast the model can inference is really based upon your memory bandwidth. 

Of the chip and oh okay if I want to increase the memory bandwidth of chip I spend $50 more dollars of. 
**[35:00]** Hardware. I pass on the cost to the customer. It's $100 more for the iPhone.


**[35:04]** Great. With a hundred bucks, I could have I could have a hundred million tokens, right? And it's I'm.


**[35:10]** Not consuming 100 million tokens. Or better yet, 100 bucks I just save it and Meta will give me the model for free on.


**[35:15]** WhatsApp and Instagram and Open ADAB will give it free on chat GPT and Google will give it free on Google. Right? It's.


**[35:21]** Like it's it's really challenging from that perspective. And then lastly, um I don't agree with the latency.


**[35:27]** Standpoint, right? I think there's certain use cases where transformers make sense for latency, super tiny uh.

Next word prediction on your keyboard or a spelling. Um, but the AI workloads that are the most valuable to you and I. Are search a restaurant at this time. 

Yeah. And go find it from a personal standpoint or access to my Gmail, my calendar, that's all in the cloud. Anyways, right? Within business, there's tons of use cases. Uh, but my data is all in the cloud anyways. for personal. You and I, it's search restaurant, go through Google Maps, make all these calls, right? Go through my calendar, uh. 

Go through my email. All this data is in the cloud anyways. A B if it's more of an agentic workflow of terms of like,. Yeah, you know, I'm really feeling Italian and and find a restaurant uh that's between you and I and location. And you know, we're we're thinking about Italian, but make sure they have gluten-free options cuz he's. 

Gluten-free. You know, find me a restaurant with a reservation at 7:00 p.m. tonight. this is a deep research query and then you get a you. Get a response it's well that took minutes or we we envision the future where the AI books flights for us it's this is not a book. The flight okay it's booked it's like book the flight it's researching it's finding stuff and it comes back but it's. 

Going through the web it's going through cloud right where is the necess necessity for it to be on device and. Because of the hardware constraints even if it is a streaming tokens thing your phone cannot run llama 7B B as fast. As I can query a server, run Llama 7B and transmit the tokens back to myself, right? And no one wants to run Llama 7B. 

They want to run, you know, GPT 4.5 or 4.1 or 03 or Claude Opus or whatever, right? They want to use a good model,. Right? And those models can't possibly run on device. So, it's a really difficult place for the use cases. There with integrated with all my data, but it's in the cloud anyways. And like it's how much of my data does Meta. 

Have, does Google have, you know, does Microsoft have? Uh let me plug into all those. Or in the way anthropic is doing. It, they've they've done this MCP stuff and they're connecting in. You can connect your Google Drive to Anthropic,. Right? And it's like, oh wait, even if I don't have my data with Anthropic, they're still able to connect to it if I. 

Give them the rights to. So it's like, where is the benefit of Ondevice AI truly from a from a use case standpoint? There's certainly one from a security standpoint, but the actual use case is like, yeah, I think there's probably an. Argument for for a little bit of both. 

And it probably does skew in terms of like the total workload towards cloud, but I think there's an argument for. Doing at least a portion of the workload on device, anything that you're interacting with the device on. You. Mentioned like, you know, typing ahead and that that makes a lot of sense. 

Yeah, I I I do think AI will make its way on device. I think it'll just be very low value AI where the cost. Structure is just so low, right? I don't think people should design hardware on phones for AI that's going. To make it more expensive, right? If you're going to keep the phone the same price point, add AI capabilities, great. 

But if you're going to increase the price point, I don't think consumers will do it. How AI on device really will. Make sense is like, you know, for example, a wearable, right? An earpiece or a smart glasses. Um and there you're. Doing small bits and pieces locally, right? Image recognition, handtracking, but the actual reasoning and thinking is. 

Happening in the cloud, right? And that's sort of the the view that sort of like a lot of these wearables are. Pushing. I think I think there will be some AI on devices. Obviously, everyone's going to try. It's not like. Samsung and Apple and all these companies are going to sit on their hands. They're going to try stuff. I. 

Just think the stuff that's actually going to drive user adoption and revenue and improve customers lives is going. To be skewing towards what's on the cloud, which is why Apple has this strategy, right? Apple's building a. Couple massive data centers, right? And they're they're buying hundreds of thousands of their Mac chips and putting. 

Them in data centers. They hired Google's head of rack architecture for the TPU, Andy, to make an they're. Making an accelerator, right? They see cloud as where AI needs to go. They just also have to push it on. Device. But even Apple themselves, although they won't say it, wants to run a lot of this in the cloud. Yeah. And. 

They do have the they have great chips to do that too. Um okay, speaking of chips, let's let's talk about Nvidia. Versus AMD. I have read a couple articles out of artificial analysis uh um sorry, semi analysis. Um lately that have kind of said that. These new AMD chips are actually really strong. Do you think AMD with their new chips h is that enough to really. 


**[40:01]** Tackle the CUDA mode or or are they going to start taking market share from Nvidia? So I think it's a confluence of.


**[40:07]** Things, right? So AMD is trying really hard. Their hardware is behind in some factors especially against.


**[40:15]** Blackwell. Um but there are some ways their hardware is better, right? Um and I think the real challenge for them is.


**[40:22]** Like you mentioned software, right? the developer experience on AMD is not that great. It's getting better. Um, you.


**[40:29]** Know, we we've we've we've asked them to do a lot of things to change it like specific fixes and changes on CI.

Resources and all these other things. 

Um, you know, there there's a long list of recommendations. We provided them in December and again more recently. Um,. And and they've implemented a number of them a good number of them, but it's like there's just so they're so far. Behind on software. It's it's incredible. Now, are they going to gain some share? I think they are going to. 

Get some share, right? Um they had some share last year and they're going to get some share this year. Um the challen the. Challenge is versus Nvidia's Blackwell, it's just objectively worse, right? As a chip. Uh oh. The chip alone,. Not the ecosystem. The chip alone. Okay. 

Um because of the system, right? Uh because Nvidia is able to connect network their chips together because of. The networking hardware they've put on their chip with NVLink, right? Um, so the way that Nvidia can build their. Servers is 72 of them work together really tightly, whereas AMD currently they can only have eight of them work. 

Together really tightly. And so this is really important for inference and training. Um, and then Nvidia's got this. Software stack. It's not just CUDA, right? Like people talk about it's just CUDA, but a lot of people don't touch. CUDA, right? Most researchers don't touch CUDA. What they do is they like call PyTorch and then PyTorch calls down. 

To CUDA and automatically it runs it runs on the hardware, right? Whether it's compile or eager mode. uh whatever you're doing, right? It generally just maps to Nvidia. Hardware really well. In the case of AMD, it doesn't as well. And now even less than that, so many people aren't. 

Even touching PyTorch, right? They're going to VLM or SG Lang, which are inference libraries. They're downloading. The model weights off of HuggingFace or wherever, right? Um and they're plugging it into this inference engine, which is. An open source repository on on GitHub, either GitHub or either SGLANG or VLM. and then they're just saying go and. 

Then those things are calling you know torch compile and those things are calling CUDA and or Triton. And just there's all these libraries down the stack really the end user just wants to use a model right. They want tokens that's and Nvidia's building libraries here called Dynamo that make this so much easier for the. 

User and now obviously there are people like open AIs of the world and others who will go all the way down to the. Bottom right deepseeks and open ais and metas and stuff but a lot of users just want to call the open. Source library, tell them, you know, hey, here's my model weights, run. 

Here's the hardware run. Right? Um, and here AMD is trying really hard, but it's still a worse user experience. Not that. It doesn't work, but it's that like, hey, if I want to use this library, it's for Nvidia, there's 10 flags. For AMD, there's 50 flags, right, that I can, you know, in each of these flags, there's different settings. And it's. 

Like, well, what's the best performance? I don't know, right? Like, you know, so so AMD, I think, is is getting there, right? They're getting there. Really fast, and they're going to get some share. Um the other aspect is Nvidia is not doing themselves favors. 

There's this ecosystem of cloud companies, right? You know, of course, everyone knows about the Google's,. Amazon's, um, you know, Microsoft, Azures, right? Those guys have been building AI chips and Nvidia's been. Trying to which and Nvidia's got AI chips obviously they've always been in contention for a while and so Nvidia as. 

A response propped up all these other cloud companies, Coreeave and Oracle, not propped up, really prioritized. Them. Oracle, but there's actually over 50 cloud companies out there, Nebius and Together and Lambda and you just go down. The list. There's all these different cloud companies that Nvidia's really helping, right? They're they're taking. 

What would have been allocations to Amazon and Google and others and saying, "Hey, you guys you guys can buy them,. Right? Is that is that to kind of level more of a commodity, right? I mean, like you go look at Amazon's margins on GPUs. They're charging $6 an hour if you were to just rent a GPU without talking to anyone, right? Which is the cost. 

To buy an Nvidia GPU and deploy it in a data center is a $140 an hour, right? That's the cost. So then like. What's a reasonable amount of profit for the cloud? Maybe $2, maybe $1.75, right? That's what Nvidia wants. They don't want all the profit being sucked up $6 on Amazon. Now obviously you can. 

Negotiate with Amazon and get much lower, right? Um but you don't want to just Yeah, it's just it's like. Really tough. So Nvidia is propping up all these different cloud companies which is driving down the price. But now. They've made a big major misstep in my opinion. They acquired this company called Leptton who does who doesn't. 

Own data centers themselves but they built all the cloud software for reliability for making it run easily you. Know storm Kubernetes all this kind of like scheduling stuff. This is stuff the clouds do right which the big clouds do. The neoclouds the new cloud companies that anybody's propping up do. But now Nvidia's bought this company that does. 

This software layer and they're doing this thing called DGx leptton which is if anyone has a cloud with spare. 
**[45:02]** Resources GPUs just give them to us and we'll rent them for you and we'll just give it to us bare metal no.


**[45:08]** Software on them and we'll add all of this leptton software on top and rent it out to users. Now the cloud companies.


**[45:14]** Are really mad at this because it's like you're direct directly competing with me right? Um, and in fact, I think Nvidia.


**[45:20]** Is also going to put some of their own GPUs on Lepton potentially that they're they're installing themselves.


**[45:25]** But it's you you're you propped us all up, but now you're making a competing cloud. So, a lot of clouds are.

Mad. They won't say it to Nvidia because Nvidia is sort of God, right? You know, like you don't you don't mess with God,. Right? What Jensen giveth, Jensen taketh. But they'll tell us the clouds are really bad, right? Um and so. So there's this aspect and so there's some cloud companies that are turning to AMD maybe partially out of. 

AMD paying them partially out of AMD being invid being them being mad at Nvidia but some of these cloud. Companies are now buying AMD GPUs and then this there's this third thing that AMD is doing which is they're taking. They're doing sort of what everyone accused I don't know if you've seen this core weave Nvidia fraud nonsense sending. 

Revenue back and forth fraud because Nvidia pays them it's yeah Nvidia Nvidia rented one cluster from them. Yeah, cool. Um, seems business as usual. It doesn't seem they need these GPUs internally, right? They have. To develop their software. I mean, there's a little something there, but it seems Yeah, exactly. They. 

Invested a tiny amount of money, right? But whatever. It's so irrelevant, right? Like but AMD is actually doing this and taking it. To overdrive. They're getting clusters at Oracle and Amazon and Crusoe and Digital Ocean and TensorWave and they're. Renting GPUs back from them, right? So, they're selling them GPUs and renting them back. Like, it's one thing if Coree. 

Like buys Nvidia GPUs and a small portion of them go to Nvidia, but the vast majority are going to Microsoft for. Open AI. You're not calling this like accounting trickery though, right? It's not accounting trickery. It's like. Perfectly the accounting is legal. 

Obviously, you can sell someone something and then rent something from them. Like Nvidia's done this too. They're almost funding the investment. Right. Right. Right. Exactly. And so this is sort of in the case of Oracle and Amazon, it's like, hey, buy our. 

GPUs. We'll rent them back. You'll see that it's great and you can actually have some some of them you won't we. Won't rent back. Some of them you'll try and rent to your customers. So that drums up interest and if it works out,. You can buy more, right? This is their this is their reasoning, right? Um or for the NeoClouds, it's like, well, you. 

Guys are only buying Nvidia stuff. Why don't you buy our stuff? here's here's a contract to get you comfortable and yeah. Here's a portion that you can rent out to other people right it's like this makes sense to some extent but it's. Also to some extent a lot of the sales are just AMD buying them back but it's this fosters really good it's. 

Like really good relations right now TensorWave and Cruso who are clouds they're I love AMD right because. They're renting GPUs for me and they're selling them to me and they're renting them back and I make a profit off of. This and now I can reinvest this in more AMD GPUs or I have a chunk of AMD GPUs I can rent to other people. Um, and. 

Meanwhile, these clouds are like, well, Nvidia is trying to compete with me anyways. Like, what what else am I. Going to do? So, it's it's a it's an interesting confluence. I think AMD will do well. I don't think. They'll surge in market share, but I think they'll do okay, right? Like, I think they'll they'll sell billions of. 

Dollars of chips, but if you're advising a company on which chipset to invest in for the foreseeable future, you're. Seeing Nvidia. Depends on the price you can get from AMD. I think there's a price where it makes sense to use AMD. And I think AMD will sometimes offer that price to people. Meta uses AMD a good bit. They also use a lot of Nvidia. 

They use a good bit of AMD. For certain workloads where AMD is actually better, uh, when I have the software talent and. AMD is giving me a ridiculous price, yeah, you should do it. And that's why Meta does it, right? But in a lot. Of workloads, Meta still goes to Nvidia because that Nvidia is the best. I want to talk about XAI. I want to talk about. 

Grock 3.5. Obviously, we at least publicly there's not a ton of information about it. Elon Musk has said. It's by far the smartest AI on the planet and it's going to operate on first principles. Uh is this is this all. Puffery? Have they actually discovered something new and unique? Uh specifically that he asked for divisive. 

But true facts there there's a lot of things that he's doing where um it just seems either he discovered. Something new or it is pure puffery. What what's your take on what's going on? I think Elon is a fantastic engineer, engineering manager, but I also think. 

He's a fantastic marketer. Um, I don't know what the new model will look like. I've heard it's good, but you've heard it's good. Everyone's heard it's good, right? So, uh, you know, we'll see what. It comes out. U, when Grock 3 came out, I was pleasantly surprised. Absolutely. 

Um, because I was expecting it to be a little bit worse, but it was actually better than I expected. Do you use Grock. 3 dayto day? day-to-day I don't but there's certain queries I do send to it well what if you don't mind me. Asking their deep research is much faster than open AI so I use that sometimes and then sometimes like. 

Models are just pansies about like giving me data right that I want right it's it's like sometimes I'm just curious what is. 
**[50:02]** The I human geography the history of humanity how geography politics history resources like interact with each other and so I like.


**[50:11]** To I to know demographics and things that as well, right? It's just interesting stuff. You know, the.


**[50:16]** Town I grew up in, right, is it's like on the Bible belt. It's half black, half white, 10,000 population. But.


**[50:22]** Like the one of the ways I describe it to people is like, well, yeah, it's like where the where the flood planes used.


**[50:27]** To be and the ocean receded, it's extremely fertile land. And that's when in Georgia when when when white settlers.

Settled everywhere randomly happened to one of the more fertile areas, so they were able to have better harvest and. They were able to then purchase slaves and that's why it's a higher black percentage than most of the state. And I. Was like, that's an insane thing to say, but I to reason about like sort of human geography this and. 

Like rock is okay with doing that, right? So sometimes it lets me under and obviously slavery is bad and that's it's. Like but just to understand like or hey why oh like invasions from the step to Europe were not because they just wanted to. Invade it's because it was becoming more aid and so they had they were like forced off their land and you know. 

Like these sorts of things are cool and interesting or economic history right like why why did Standard Oil win versus. This other oil company right before it got to monopoly levels right it's like these sorts of things are just. Interesting to learn but other models will start if it's the standard oil thing, it'll be like, "Oh, it was a union buster, blah, blah,. 

Blah." It's like, "No, just tell me like what actually happened, right?" And so, like, I think Grock can sometimes. Get through the but it's also not the best model. So, my daily the model I go to the most is either 03. Or Claude 4. Um, you're using 03 daytoday, even though there's, you know, it takes so much time to actually get. 

Your response back. It depends on the topic, but yeah, I think I think a lot of times I'm okay with waiting. A lot of. Times I'm not. That's why I use Claude. I use Gemini in in work, right? So, we feed a lot of permits and regulatory filings through Gemini. We feed a lot of. 

Like u long it's really good at long context, right? And document uh analysis and retrieval. So, we feed a. Lot of stuff through Gemini in a workplace manner, but I'm talking about pull out my phone, I want to know. Something mid-con conversation or whatever. It's a different model. So, okay. So, so back to So, Grock, yeah,. 

Grock, they they have a lot of compute. It's really concentrated. They have a lot of great researchers. Will they, you know, they've got 200,000 GPUs. Already up. Um, and they've purchased a new factory in Memphis and they're building out a new data center and. 

They're shi, you know, you know, there's the craziness they did with mobile generators. Well, now they just bought a. A power plant from overseas and are shipping it to the US because they couldn't get a power plant uh, you know,. A new one in time. So, they're doing all this crazy to get the compute. They've got good researchers. 

Clearly, the models are good and Elon's hyping them up. Maybe it'll be great. Maybe it'll be good. Maybe, you know, will it be opening eye level or it'll be like just slightly behind, you know, I. Don't know. But are they doing something fundamentally different? He specifically said rewrite the corpus of human. 

Knowledge because too much garbage is in the current foundation models that I mean he must e obviously he has. The x data which is insane but it's also really low quality so it's hard to get through. Right. So but also at the same. Time oh that's another area where I use grock sometimes current events. Um, yeah, summarizing or giving you the. 

Contiles are happening in Israel and Iran and all this war stuff. You can actually ask Grock and it tells you what. Exactly what's happening way better than uh a Google search will or even a Gemini query or open query because it it's got. Access to all this info. Yeah. So, are they doing anything different? I I like like step function different we're. 

I think step function differentwise I don't think anyone is like everyone likes to think they're doing. Different things but generally people are doing the same thing. They're pre-training large transformers and. They're doing RL on top mostly in verifiable domains although they're researching how to do unverifiable. 

Domains. It's it's it's like oh yeah they're making environments to to for the model to play in but they're. Mostly code and math but now they're getting into computer use and you know all these other things. It's like. Everyone's doing generally the same stuff, but there's such a it's also like such a challenging problem. There's many. 

Directions to go with it, but I think generally everyone's doing going the same approach. Even SSI is not I I. Imagine SSI is doing some different stuff, but I don't even think they're doing that much differently than than. What I just said. I have kind of two different topics I want to let you maybe choose. Uh economics, labor. So, I want. 

To talk about the 50% of white collar jobs could disappear. I know you probably read about that or um. Non-verifiable rewards which you know obviously that's maybe more recent more on your mind. You have any preference? Um I think the prior is more I mean maybe maybe the latter is more interesting for your your your your. 

Audience. I'm not sure but the prior is really interesting right in terms of like everyone's worried about massive. Job loss right or at least some people are in the AI world but then the flip side is that you know populations are aging really rapidly and. Generally people work less than ever before right we make fun of Europeans because they work really a lot. 

Less but the average amount of hours worked 50 years ago was way higher right and 100 years ago is even higher. 
**[55:04]** Than that and the amount of leisure time was way less and the size of everyone's home is way larger and the food.


**[55:10]** Security is way better. It's every metric were way better than 50 years ago or 100 years ago and AI should just.


**[55:16]** Enable us to work even less right now.


**[55:18]** Is it going to be there's going to be psychos like myself and probably yourself as well that work way too much.


**[55:24]** Um and then there's going to be like normal people who work way less, right?


**[55:28]** And and obviously the distribution of resources is the challenge though, right? Um I think that's the big thing. Um, that's why I'm.

Super excited about robotics as well because robotics is uh, you know, a lot of jobs that are easier to automate. Are are hardest to automate are robotics influenced and the stuff people want to do is sit on a computer and be creative,. 

But actually that's one of the markets that's been nuked the hardest is freelance graphics designers, right? And. What's the market that's not touched is picking fruit, right? And it's it's that's the that people don't want to do. And it still seems that's way in the future even though robotics has been. 

Progressing at an in an insane rate, but it does seem it's pretty far in the future still. Okay. But do you. Foresee as human productivity increases like crazy? Uh certainly a a large swath of tasks will be automated do you. Think humans are going to be managing AI in the future or are we going to be reviewing the output of AI or some. 

Mixture of in between? Right now we're in the transition from using models on a chat basis to a longer horizon basis. You know I mentioned I used 03 a lot because actually there's a lot of longer horizon tasks. Now these longer horizon. Tasks are 20 30 seconds and deep research is dozen minutes right dozens of minutes. Um, over time these like. 

Interactions with AI will become obviously there will be an AI assistant that I'm just talking to all the time or. Will be telling me stuff that is not noteworthy, but there will also be just long horizon tasks of AI is going. To be doing stuff for hours, days before coming back for me to review and then eventually there just won't be. 

Humans in the loop, right? Um, and eventually do you believe that? And like what timeline are you thinking? Uh, I. Think timeline questions are ridiculous. I'm I'm generally more pessimistic on timelines. It's not I don't think this decade for people to for like. 

20% of jobs to be automated I think it's like not it's maybe the end of this decade maybe the beginning of next. For 20% of jobs to be automated right meanwhile there's people saying AGI in 2027 u but their definition but reaching. Tech doesn't mean the implementation is going to happen at that moment either right it's going to take years before we. 

Actually are are able to deploy it in the field I think I think deployment will be really fast you already see the. Junior software engineering market is nuked no one can get a You can already see the usage of AI and software. Development is skyrocketing. Um and we're not even at automated software development yet. We're just at code. 

Assistant. Are companies going to choose to do more things? Are they going to choose to tackle more problems? Yes. So. Then how do those junior engineers get into the market to begin with? Then I assume I spoke to Aaron Levy. Yesterday and he was no as soon as a team tells me look how productive we are. Where do you think I'm going to. 

Invest? I'm going to invest back in that team. We're going to grow that team. um where is the place for junior engineers. Then? Yeah, I think I think that's nice and I agree and I myself my company does a bunch of stuff but but. Due to the use of AI we can do a whole lot more stuff and that makes us more productive and we're able to out compete. 

The old firms that don't do stuff in the consulting and data space. Um but it's I still I still have. Like basically doubled the size of the firm in the last year to 32 now 33. How many junior software developers am I. Going to hire? It's no, it's like the junior software developer I have like we just cheered her on because she. 

Just did 50 commits last week and it's that's what used to take many more people. It's how much stuff there's obviously a lot of. Software for us to build. Um but it's like how many people can we like actually add right and it's wouldn't I rather have. Like a senior person that's like commanding a bunch of AIs rather than like a junior person. So it's sort. 

Of it's challenging u at the same time hiring young people because they can't they do they can quickly adapt to the new AI tools right. Sort of it's a it's a it's a a balancing act. Um, I think it's I think it's I don't know where the junior. Software developers would go because I get people pinging me on Twitter and LinkedIn all the time you have. 

A job for me. It's no I don't really but or sometimes I do, right? But it's it's tough and I don't see the major tech companies. Hiring junior software developers that much, right? Um it's just a fact, right? And that's why the market is really bad. 

Um, so they had to just self-skill up on their own. Come come come with better skills. But or try and build stuff on. Their own and show that they're not a junior software developer, but they can actually use these tools. That's not for. Everybody though. Yeah, it's not it's not People A lot of people just need a job. They don't need to selfart and. 

Like they don't want to be founders for sure. They don't want to be kind of solo builders. Even if you're not a founder,. They want to have that. Yeah. I mean, that's been a problem for me is like when I started hiring people is like. Some people need a lot of direction and I don't have direction to give. I'm like, I need self starters. Right now. 


**[60:02]** There's people who can do that in the firm but it's like it's tough to give people you know people some people just need direction.


**[60:08]** And need more handholding at least initially open source versus closed source and why the US is going to lose.


**[60:14]** In open source unless Meta gets dramatically better which they are. I think with a lot of the talent they're.


**[60:21]** Hiring. I think Sam is wrong that they're not getting any top researchers.


**[60:24]** Um Sam Alman I think they are there's some top researchers I know for sure are going there. um maybe not the first people they offered,.

Right? Like the ones that have the highest highest profile, but there are still some top researchers going there. 

China is open sourcing stuff only because they're behind. The moment they're ahead, they will stop open. Sourcing stuff. And at the end of the day, closed source will win. Um unfortunately, close source will win. My. Only hope is that it's not just two or three closed source AIs that like dominate human GDP, right? Or or types. 

Of models or companies, right? But rather it's more distributed than that. But it might not be right. Meta,. Google, Open AAI, Microsoft, Tesla, whoever else, you had to pick one company to bet on. Super intelligence. Reaching it first. Who are you picking and why? Open AI. Um, they're the first to every major breakthrough. Um, even. 

Reasoning, they were the first two. Um, and I don't think reasoning alone will take us to the next generation. So,. There's going to be something else. Enthropic second. Um, third would it's a topic. They're so conservative though. 

They're so conservative at Enthropic in terms of what they release, what they publish, what they focus on. So much. Safety. I mean, I think has weakened a lot. I think they're a lot less conservative than they used to be. Okay. Um, the process for launching Cloud 4, as far as I understand, was much simpler and easier than the process for. 

Launching Cloud 3. Whether it's that they're hiring a lot more normies, which they are. or they recognize that. Others are just going to release stuff anyways and they should have theirs or whatever it is. I think Anthropic is. Like loosening up a bit. I think they just have really good people though. Um and then sort of third is going to. 

Be it's actually a toss up between Google XAI and and X and and Meta now. I think Meta will get enough good. People that they'll actually be competitive too. Dylan, thank you so much for chatting with me. Thanks for. Having me. Appreciate it. This is awesome, man. Yeah, very fun. Yeah, you can talk about anything, huh? Maybe. 

Maybe. 